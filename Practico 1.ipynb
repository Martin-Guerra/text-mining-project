{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminacion de ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierto los archivos html en objetos soup para posterior analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"framechapter1.html\") as fp:\n",
    "    soup1 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter2.html\") as fp:\n",
    "    soup2 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter3.html\") as fp:\n",
    "    soup3 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter4.html\") as fp:\n",
    "    soup4 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter5.html\") as fp:\n",
    "    soup5 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter6.html\") as fp:\n",
    "    soup6 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter7.html\") as fp:\n",
    "    soup7 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter8.html\") as fp:\n",
    "    soup8 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter9.html\") as fp:\n",
    "    soup9 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter10.html\") as fp:\n",
    "    soup10 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter11.html\") as fp:\n",
    "    soup11 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter12.html\") as fp:\n",
    "    soup12 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter13.html\") as fp:\n",
    "    soup13 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter14.html\") as fp:\n",
    "    soup14 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter15.html\") as fp:\n",
    "    soup15 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter16.html\") as fp:\n",
    "    soup16 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter17.html\") as fp:\n",
    "    soup17 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter18.html\") as fp:\n",
    "    soup18 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter19.html\") as fp:\n",
    "    soup19 = BeautifulSoup(fp)\n",
    "\n",
    "with open(\"framechapter20.html\") as fp:\n",
    "    soup20 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter21.html\") as fp:\n",
    "    soup21 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter22.html\") as fp:\n",
    "    soup22 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter23.html\") as fp:\n",
    "    soup23 = BeautifulSoup(fp)\n",
    "    \n",
    "with open(\"framechapter24.html\") as fp:\n",
    "    soup24 = BeautifulSoup(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llevo todos los soup a la primera etiqueta p, que es donde esta la parte que queremos analizar; el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = soup1.p\n",
    "soup1 = soup1.get_text()\n",
    "\n",
    "soup2 = soup2.p\n",
    "soup2 = soup2.get_text()\n",
    "\n",
    "soup3 = soup3.p\n",
    "soup3 = soup3.get_text()\n",
    "\n",
    "soup4 = soup4.p\n",
    "soup4 = soup4.get_text()\n",
    "\n",
    "soup5 = soup5.p\n",
    "soup5 = soup5.get_text()\n",
    "\n",
    "soup6 = soup6.p\n",
    "soup6 = soup6.get_text()\n",
    "\n",
    "soup7 = soup7.p\n",
    "soup7 = soup7.get_text()\n",
    "\n",
    "soup8 = soup8.p\n",
    "soup8 = soup8.get_text()\n",
    "\n",
    "soup9 = soup9.p\n",
    "soup9 = soup9.get_text()\n",
    "\n",
    "soup10 = soup10.p\n",
    "soup10 = soup10.get_text()\n",
    "\n",
    "soup11 = soup11.p\n",
    "soup11 = soup11.get_text()\n",
    "\n",
    "soup12 = soup12.p\n",
    "soup12 = soup12.get_text()\n",
    "\n",
    "soup13 = soup13.p\n",
    "soup13 = soup13.get_text()\n",
    "\n",
    "soup14 = soup14.p\n",
    "soup14 = soup14.get_text()\n",
    "\n",
    "soup15 = soup15.p\n",
    "soup15 = soup15.get_text()\n",
    "\n",
    "soup16 = soup16.p\n",
    "soup16 = soup16.get_text()\n",
    "\n",
    "soup17 = soup17.p\n",
    "soup17 = soup17.get_text()\n",
    "\n",
    "soup18 = soup18.p\n",
    "soup18 = soup18.get_text()\n",
    "\n",
    "soup19 = soup19.p\n",
    "soup19 = soup19.get_text()\n",
    "\n",
    "soup20 = soup20.p\n",
    "soup20 = soup20.get_text()\n",
    "\n",
    "soup21 = soup21.p\n",
    "soup21 = soup21.get_text()\n",
    "\n",
    "soup22 = soup22.p\n",
    "soup22 = soup22.get_text()\n",
    "\n",
    "soup23 = soup23.p\n",
    "soup23 = soup23.get_text()\n",
    "\n",
    "soup24 = soup24.p\n",
    "soup24 = soup24.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntamos todos los soup conseguidos en uno solo para poder analizar el texto completo en una sola variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup (soup1 + soup2 + soup3 + soup4 + soup5 + soup6 + soup7 + soup8 + soup9 + soup10 + soup11 + soup12 + soup13 + soup14 + soup15 + soup16 + soup17 + soup18 + soup19 + soup20 + soup21 + soup22 + soup23 + soup24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos ahora los saltos de linea y finalizamos la etapa de eliminacion de ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\n",
    "for string in soup.stripped_strings:\n",
    "    texto = texto + repr(string)\n",
    "    \n",
    "soup = BeautifulSoup (texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos las contracciones de las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "soup = soup.get_text()\n",
    "soup = contractions.fix(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la libreria nltk, necesaria para generar los tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo las oraciones en palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "texto = word_tokenize(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso a minusculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_minusculas(texto):\n",
    "    new_words = []\n",
    "    for word in texto:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "texto = a_minusculas(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminacion de signos de puntuacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remover_puntuacion(texto):\n",
    "    new_words = []\n",
    "    for word in texto:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "texto = remover_puntuacion(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion de numeros a sus equivalentes en texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "\n",
    "def reemplazar_numeros(texto):\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in texto:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "texto = reemplazar_numeros(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtencion de las stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def get_stopwords(texto):\n",
    "    stop_words = []\n",
    "    for palabra in texto:\n",
    "        if palabra in stopwords.words('english'):\n",
    "            stop_words.append(palabra)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminacion de las stopwords obtenidas en el metodo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_stopwords(texto):\n",
    "    new_words = []\n",
    "    stopwords = get_stopwords(texto)\n",
    "    for word in texto:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "texto = remover_stopwords(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtencion de stemmers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "texto = list(stemmer.stem(t) for t in texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa de lematizacion. Implementamos los dos procesos a fin de llevar un analisis mas completo del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lematizador = nltk.WordNetLemmatizer()\n",
    "texto = list(lematizador.lemmatize(t) for t in texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploracion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion de un grafico de dispersion para observar las palabras mas usadas en el texto analizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5dc70db3ccba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpalabras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'little'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prince'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sheep'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'planet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'astronomer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'king'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rose'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprobabilidades\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.03\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.27\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yellow'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'purple'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#DD98AA'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#18492D'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrafico\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobabilidades\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpalabras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautopct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%1.1f%%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "palabras = ('little', 'prince', 'sheep', 'planet', 'astronomer', 'king', 'rose')\n",
    "probabilidades = (0.1, 0.3, 0.05, 0.15, 0.1, 0.03, 0.27)\n",
    "color = ('red', 'blue', 'green', 'yellow', 'purple', '#DD98AA', '#18492D')\n",
    "_, _, grafico = pyplot.pie(probabilidades, colors=color, labels = palabras, autopct = '%1.1f%%')\n",
    "for graf in grafico:\n",
    "    graf.set_color('black')\n",
    "pyplot.axis('equal')\n",
    "pyplot.title('Grafica de dispercion de palabras')\n",
    "pyplot.show()\n",
    "pyplot.savefig('grafica.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
